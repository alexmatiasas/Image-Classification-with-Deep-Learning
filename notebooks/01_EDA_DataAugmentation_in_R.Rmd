---
title: "EDA and Data Augmentation on CIFAR-10"
output: 
  html_document:
    toc: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(ggplot2)
library(gridExtra)
```

# Image Structure Exploration
In this section, we start by exploring the structure of individual images in the CIFAR-10 dataset.
Each image is 32x32 pixels with 3 color channels (Red, Green, Blue).

In the code below, we import the **CIFAR-10 dataset** from local files using the `numpy` library via the `reticulate` package.  
We also **select a random sample of 1000 images** to perform **exploratory data analysis (EDA)** on a manageable subset.

```{r load-data}
# Import numpy via reticulate
np <- import("numpy")

# Load the data
x_train <- np$load("../data/raw/x_train.npy")
y_train <- np$load("../data/raw/y_train.npy")

# Optional: sample subset
sample_idx <- 1:1000
x_sample <- x_train[sample_idx,,,]
y_sample <- y_train[sample_idx,]
```


# 1. **Visual Exploration**:

## Channel Separation

The first visualization splits the first image into its three RGB channels.
This allows us to understand how information is distributed across channels.


```{r visualize}
# Convert first image to dataframe for ggplot
img <- as.data.frame(as.table(x_sample[1,,,]))
colnames(img) <- c("x", "y", "channel", "value")

# Plot first image (RGB split)
ggplot(img, aes(x = x, y = y, fill = value)) +
  geom_tile() +
  facet_wrap(~ channel) +
  scale_fill_gradient(low = "black", high = "white") +
  theme_void() +
  ggtitle("First CIFAR-10 Image (Channels)")

plot_rgb_image <- function(image_array) {
  img <- image_array / 255  # Normalize
  dimnames(img) <- list(x = 1:32, y = 1:32, channel = c("R", "G", "B"))
  
  # Convert to dataframe for ggplot
  df <- as.data.frame(as.table(img))
  df <- reshape2::dcast(df, x + y ~ channel, value.var = "Freq")
  
  # Convert x and y to numeric
  df$x <- as.numeric(as.character(df$x))
  df$y <- as.numeric(as.character(df$y))
  
  ggplot(df, aes(x = x, y = y)) +
    geom_tile(fill = rgb(df$R, df$G, df$B)) +
    scale_y_reverse() +  # Flip y-axis for image orientation
    theme_void() +
    ggtitle("First CIFAR-10 Image (RGB)")
}

# Using the function to plot the first image
plot_rgb_image(x_sample[1,,,])
```

- **Observations**
  - Each channel (Red, Green, Blue) captures different intensities of light.
  - The combined result (full RGB) blends these channels to form the final color image.

**Full RGB Reconstruction** 

The following image shows the full RGB reconstruction of the first image, which is a combination of the three channels.

- **Observations**
  - The full RGB image appears more colorful and detailed compared to the individual channels.
  - Normalization (0-1 range) ensures that pixel intensities are scaled properly, which is crucial for model training stability later.

## Sample Images Overview

After analyzing the structure of individual images, we proceed to visually inspect a broader sample from the dataset.
This step helps confirm the diversity of the images and ensures that the preprocessing pipeline (e.g., normalization) has been applied correctly across the dataset.

### First 9 Images from the Sample

The following grid displays the first 9 images from the selected sample of 1000 images:

```{r images-grid}
library(gridExtra)
library(grid)

plot_rgb_image_no_title <- function(image_array) {
  img <- image_array / 255
  dimnames(img) <- list(x = 1:32, y = 1:32, channel = c("R", "G", "B"))
  df <- as.data.frame(as.table(img))
  df <- reshape2::dcast(df, x + y ~ channel, value.var = "Freq")
  df$x <- as.numeric(as.character(df$x))
  df$y <- as.numeric(as.character(df$y))
  
  ggplot(df, aes(x = x, y = y)) +
    geom_tile(fill = rgb(df$R, df$G, df$B)) +
    scale_y_reverse() +
    theme_void()
}

# Muestra las primeras 9 imágenes
plots <- lapply(1:9, function(i) plot_rgb_image_no_title(x_sample[i,,,]))
grid.arrange(grobs = plots, ncol = 3)
```

- **Observations**
  - The dataset contains varied classes (e.g., animals, vehicles).
  - The images exhibit different colors, backgrounds, and orientations, which helps in challenging the model during training.
  - The Normalization step has not affected the visual quality.

**Purpose of this Step**
- Visual confirmation that the dataset includes diverse examples.
- Ensures that the preprocessing pipeline works consistently across the dataset.

## Class Distribution Analysis

To ensure the dataset is balanced across different categories, we analyze the class distribution of the CIFAR-10 sample.

The CIFAR-10 dataset contains 10 classes:

- airplane
- automobile
- bird
- cat
- deer
- dog
- frog
- horse
- ship
- truck

### Distribution Plot (Sample of 1000 Images)

```{r class-labeling}
# Class names in CIFAR-10
class_names <- c("airplane", "automobile", "bird", "cat", "deer",
                 "dog", "frog", "horse", "ship", "truck")

# Convert labels to dataframe with class names
labels_df <- data.frame(label = factor(y_sample, levels = 0:9, labels = class_names))

# Plot class distribution
ggplot(labels_df, aes(x = label)) +
  geom_bar(fill = "steelblue") +
  theme_minimal() +
  labs(title = "Class Distribution (Sample of 1000 Images)", x = "Class", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

- **Observations**
  - The dataset is balanced across the 10 classes in this 1000-image sample.
  - This balance helps ensure that models trained on this data won’t be biased toward any specific class.
  
**Purpose of this Step**

- Confirm that the sample selection maintains class balance.
- Identify any potential imbalance issues early on.

## Class-wise Image Exploration

To further assess the diversity within each class, we display a grid of 9 sample images per class (total of 90 images).
This helps visualize the intra-class variation, including different backgrounds, colors, and orientations.

### Grid of 9 Images per Class

```{r images-classes}
library(gridExtra)
library(ggplot2)

# Class names in CIFAR-10
class_names <- c("airplane", "automobile", "bird", "cat", "deer",
                 "dog", "frog", "horse", "ship", "truck")

# Create a dataframe to map labels
labels_df <- data.frame(
  index = 1:length(y_sample),
  label = factor(y_sample, levels = 0:9, labels = class_names)
)

# Function to plot one image
plot_rgb_image_label <- function(image_array, label) {
  img <- image_array / 255
  dimnames(img) <- list(x = 1:32, y = 1:32, channel = c("R", "G", "B"))
  df <- as.data.frame(as.table(img))
  df <- reshape2::dcast(df, x + y ~ channel, value.var = "Freq")
  df$x <- as.numeric(as.character(df$x))
  df$y <- as.numeric(as.character(df$y))
  
  ggplot(df, aes(x = x, y = y)) +
    geom_tile(fill = rgb(df$R, df$G, df$B)) +
    scale_y_reverse() +
    theme_void() +
    ggtitle(label)
}

# Select 9 images per class
plots <- list()
for (class in class_names) {
  indices <- labels_df$index[labels_df$label == class][1:9]
  class_plots <- lapply(indices, function(i) plot_rgb_image_label(x_sample[i,,,], class))
  plots <- c(plots, class_plots)
}

# Arrange plots in a grid (9 columns)
grid.arrange(grobs = plots, ncol = 9)
```

- **Observations**
  - **Intra-class diversity**:
    - Some classes (e.g., airplane, automobile) display a wide range of angles, colors, and backgrounds.
    - Others (e.g., frog, dog) show variability in poses and lighting.
  - **Class overlap potential**:
    - SSome images (e.g., ship vs. truck or dog vs. cat) could present classification challenges due to visual similarities in certain cases.
    
**Purpose of this Step**
- Provides visual confirmation of dataset richness within each class.
- Helps anticipate potential difficulties in classification, such as overlapping features between certain classes.

# 2. **Pixel Intensity Analysis**

## Channel-wise Statistics (Mean and Standard Deviation)

After exploring the visual structure of the images, we calculate the mean and standard deviation for each RGB channel across the 1000-image sample.
This helps us understand the distribution of pixel intensities numerically.

```{r mean-and-std}
# Calculate mean and standard deviation for each RGB channel

# Normalize the pixel values to the range [0, 1]
x_sample_norm <- x_sample / 255

# Compute the mean for each channel (Red, Green, Blue)
channel_means <- apply(x_sample_norm, 4, mean)

# Compute the standard deviation for each channel
channel_stds <- apply(x_sample_norm, 4, sd)

# Create a dataframe to display the statistics
channel_stats <- data.frame(
  Channel = c("Red", "Green", "Blue"),
  Mean = round(channel_means, 4),
  Std_Dev = round(channel_stds, 4)
)

# Print the calculated statistics
print(channel_stats)
```

- **Observations**
  - **Mean values**:
    - The Red and Green channels have similar average intensities (~0.49).
    - The Blue channel exhibits a slightly lower mean (~0.45), suggesting less dominance of blue tones across the dataset.
  - **Standard deviation**:
    - The Blue channel shows a higher standard deviation (~0.26), indicating more variability in its pixel intensities.
    - This variability can be important for model normalization.
    
**Purpose of this Step**
- Quantifies the pixel intensity distribution across channels.
- These statistics will be used for normalization strategies (e.g., subtracting mean and dividing by std in modeling).

## Histogram of Pixel Intensities
To further analyze the distribution of pixel intensities across channels, we plot histograms for each RGB channel.

```{r histogram of RGB}
# Convert the sample dataset to a long dataframe format for histogram plotting
library(reshape2)

# Normalize the pixel values to the range [0, 1]
x_sample_norm <- x_sample / 255

# Reshape the data: Flatten X and Y, keep channels
pixel_values <- data.frame(
  Red = as.vector(x_sample_norm[,,,1]),
  Green = as.vector(x_sample_norm[,,,2]),
  Blue = as.vector(x_sample_norm[,,,3])
)

# Convert to long format
library(tidyr)
df_pixels <- pivot_longer(pixel_values, cols = everything(), names_to = "Channel", values_to = "Value")

# Plot histograms with manual colors
ggplot(df_pixels, aes(x = Value, fill = Channel)) +
  geom_histogram(bins = 30, alpha = 0.7, position = "identity") +
  facet_wrap(~Channel) +
  scale_fill_manual(values = c("Red" = "red", "Green" = "green", "Blue" = "blue")) +  # Correct RGB colors
  theme_minimal() +
  labs(title = "Histogram of Pixel Intensities by Channel", 
       x = "Pixel Intensity (Normalized)", 
       y = "Frequency")
```

- **Observations**
  - Red and Green channels display similar bell-shaped distributions centered around ~0.5.
  - The Blue channel shows a slight left shift, with a broader spread.
  - These patterns confirm the numerical statistics calculated earlier (mean and std).
  
**Purpose of this Step**
- Visual confirmation of the pixel intensity distribution.
- Helps decide normalization strategies and check for anomalies in data preprocessing.